---
pagetitle: "spatial operations with sf"
---

<br>

## Spatial Joins in R with `sf`

Some of the most common and useful geospatial operations are **joins** based on some component of the spatial topology. For example, you want to figure out what attributes of certain points that are associated with or within certain polygons on the landscape...like bus-stops in a county or river gaging stations within a watershed. 

Spatial joins are based on the intersection between two spatial objects, often points and the polygons. There are many ways we can join objects, which may include [specific options](https://r-spatial.github.io/sf/reference/geos_binary_pred.html) like *crosses*,*near*, *within*, *touches*, etc. The point being, we can do all this in R!  Robin Lovelace et al. have a great online book available: https://geocompr.robinlovelace.net/spatial-operations.html that covers some of this material. Check it out! 

Let's **load the libraries** we're going to need first.

```{r loadlibs, echo=T, eval=F}

library(here)
library(dplyr)
library(ggplot2)
library(mapview)
library(sf)
library(USAboundaries)
library(GSODR)
library(rnaturalearth)
```


```{r libseval, eval=T, echo=F, message=F, show=FALSE}

suppressPackageStartupMessages({
  library(here);
  library(dplyr);
  #library(viridis);
  library(ggplot2);
  library(sf);
  library(GSODR);
  #library(mapview);
  library(rnaturalearth);
  library(USAboundaries)
  #library(spData)
})

```

### Polygon Data

We'll be using California and CA counties pulled from the `USAboundaries` package.

```{r getBoundaryDat, echo=T, eval=T, purl=FALSE}

# get USA states, filter out Puerto Rico, Alaska, and Hawaii for now
us <- us_boundaries(type="state", resolution = "low") %>% 
  filter(!state_abbr %in% c("PR", "AK", "HI"))

# get CA boundary with high definition
ca <- USAboundaries::us_states(resolution = "high", states = "CA")

# make a box around CA (a grid with an n=1) for inset
ca_box <- st_make_grid(ca, n = 1)

# get CA county boundary
ca_co <- USAboundaries::us_counties(resolution = "high", states = "CA")

# make sure we have all the pieces with a quick test plot
plot(us$geometry)
plot(ca$geometry, add=T, col="gray50", border="maroon")
plot(ca_co$geometry, add=T, border="pink", col=NA)
plot(ca_box, add=T, border="red3", col=NA, lwd=2)

```

<br>

### Point Data

Now we have some polygon data to work with...let's add some climate data and practice joining polygons to points and points to polygons! First let's use the [`GSODR` (Global Surface Summary of the Day) package](https://ropensci.github.io/GSODR/) to get global climate station locations. Then we can join to a few specific states/counties, and plot. First the GSOD data:

```{r getGSODR, echo=TRUE, eval=TRUE, purl=FALSE}

library(GSODR)

# load the station metadata file from GSODR (this loads `isd_history` in your
# R session)
#load(system.file("extdata", "isd_history.rda", package = "GSODR"))
load(paste0(here(),"/data/isd_history.rda"))
isd_history <- as.data.frame(isd_history) %>% 
  st_as_sf(coords=c("LON","LAT"), crs=4326)  

# filter to US and CA, many sites out in buoys along coast
isd_history_ca <- filter(isd_history, CTRY=="US", STATE=="CA")

```

Note, this is a fairly large set of point data, with `r nrow(isd_history)` observations globally. Let's map this so we can see how dense this dataset actually is. Let's use a nice set of global maps from the `rnaturalearth` package. Because the points are so dense, let's plot those first, then we'll add a layer of world country outlines.


```{r plotGSODR, echo=TRUE, eval=TRUE, purl=FALSE}

# view!
library(rnaturalearth)
library(rnaturalearthdata)
world <- ne_countries(scale = "medium", returnclass = "sf")

plot(isd_history$geometry, pch=16, cex=0.2, col="gray50")
plot(world$geometry, add=T)
title("GSOD Climate Stations")

```

That's a lot of points! Let's look at just California.

```{r tstPlotCAISD, echo=TRUE, eval=TRUE, purl=FALSE}

# look at CA sites only
plot(isd_history_ca$geometry, cex=0.5)
plot(ca$geometry, col=alpha("gray", 0.5), border="#440154FF", lwd=1.5, add=TRUE)
plot(isd_history_ca$geometry, add=T, pch=21, bg="#21908CFF", cex=0.7, col="black")
title("GSOD Climate Stations labeled as CA")

```

Great, now we have a dataframe in our environment that has both global climate station locations, and only stations associated with California, USA. You'll notice there are a number of stations that fall outside of the CA border, largely those associated with buoys along the coast.

<hr>

## Spatial Joins

### Join: Select *POLYGONS* containing *POINTS*


This first approach only selects polygons that contain points. For demonstration sake, let's use the larger global point dataset. Note this does not modify polygon dataframe in any form (i.e., add attributes, update, summarize, etc). It is only selecting or *filtering* to the polygons that contain points using a spatial join. 

```{r polyptJoin, echo=TRUE, eval=TRUE, purl=FALSE}

# Get CA county POLYGONS only that contain ISD points within county boundaries
# does not bring attributes from points forward
ca_co_isd_poly <- ca_co[isd_history, ]

plot(ca_co_isd_poly$geometry, col=alpha("blue",0.3))

```

<br>

### Join: *Add POLYGON attributes* to *POINTS* inside *POLYGONS*

Now let's look for points that fall within CA counties, and add ATTRIBUTES from the county polygons to the climate station points. Just a reminder, here's the data columns (or *attributes*) in the polygon dataset:

```{r headCACOUNTY, echo=FALSE, eval=TRUE, purl=FALSE, warning=FALSE}
head(as.data.frame(ca_co))
```

So in this case, let's say we want to add the county **`name`** attribute to our POINT dataset, which looks like this (notice there's no `county` field or `name` field):

```{r headISDpt, echo=FALSE, eval=TRUE, purl=FALSE, warning=FALSE}
head(as.data.frame(isd_history))
```

So to spatially join the county `name` attribute with the appropriate point locations, let's use `st_join`. If we use `left=TRUE` here, our result will retain *all* the points in the dataset rather than just the the spatial overlaps (where points fall inside polygons). So left=TRUE` is essentially a `dplyr::left_join`, and `left=FALSE` is equivalent to a `dplyr::inner_join`.


```{r polyJoinAttribs, echo=TRUE, eval=TRUE, purl=FALSE, warning=FALSE}

# For POINTS that fall within CA_counties, adds ATTRIBUTES, retains ALL pts if left=TRUE, otherwise uses inner_join
isd_ca_co_pts <- st_join(isd_history, left = FALSE, ca_co["name"]) # join points

# plot
plot(isd_ca_co_pts$geometry, pch=21, cex=0.7, col="purple", bg="gray80")
plot(ca_co$geometry, border="gray20", col=NA, add=T)

```

```{r headISDpt2, echo=FALSE, eval=TRUE, purl=FALSE, warning=FALSE}
head(as.data.frame(isd_ca_co_pts))

```

Now we have only points that fall *inside* of a CA county, **AND** the new data frame now has a new column/attribute called "`name`" (all our climate station points have a named CA county associated with them). We could easily specify additional columns inside our `st_join` function, or if we don't specify any columns, then all columns from the polygon dataframe that spatially joined/matched the points data would be added to the points dataframe.

 > `isd_ca_co_pts <- st_join(isd_history, left = FALSE, ca_co) # join all columns`


### Plot Some Climate Data

Hopefully the above was useful...but let's actually use grab some climate data from the `GSODR` package and plot it. For this example, let's select data from Fresno. I've already downloaded it ([here]()) if you'd like to play along. I'm going to plot the weekly average temperature and precipitation for 1972-2018.

```{r polyJoinAttrib, echo=FALSE, eval=FALSE, purl=FALSE, warning=FALSE}

# check availability for a date range
loop_stations <- isd_ca_co_pts[isd_ca_co_pts$BEGIN <= 19600101 &
                               isd_ca_co_pts$END >= 20181231, ]

# use Fresno Airport: KFAT
ggplot() +
  geom_sf(data=ca)+
  geom_sf(data = loop_stations, size = 2) +
  ggtitle("Station locations")

stationID <- filter(loop_stations, CALL=="KFAT") %>% 
  select(USAF, WBAN, STNID)

# get data:
fresyes <- get_GSOD(station = stationID$STNID, years = c(1970:2018))

# save it!!
save(fresyes, file = "data/fresno_GSOD_climate_19720101-20181231.rda")



# YDAY: filter to 1980 plus:
# fresyes_yday <- fresyes %>% filter(YEARMODA > "1980-01-01") %>% 
#   filter(!is.na(PRCP)) %>% 
#   group_by(YDAY) %>% 
#   summarize_at(.vars=c("TEMP","PRCP","RH"), .funs = c(mean))
# ggplot() + geom_col(data=fresyes_yday, aes(x=YDAY, y=PRCP), col="darkblue")+
#   coord_polar()

# YEAR: filter to 1980 plus:
# fresyes_year <- fresyes %>% filter(YEARMODA > "1980-01-01") %>% 
#   filter(!is.na(PRCP)) %>% 
#   group_by(YEAR) %>% 
#   summarize_at(.vars=c("TEMP","PRCP","RH"), .funs = list(mean=mean, max=max, min=min))

# annual precip (could compare across sites?)
# ggplot() + geom_col(data=fresyes_year, aes(x=YEAR, y=PRCP_mean)) +
#   coord_polar()


```

<br>

```{r loadGSOD, eval=T, echo=F, purl=FALSE}

load(paste0(here(),"/data/fresno_GSOD_climate_19720101-20181231.rda"))

# MONTH: filter to 1980 plus:
fresyes_month <- fresyes %>% filter(YEARMODA > "1980-01-01") %>% 
  filter(!is.na(PRCP)) %>% 
  group_by(MONTH) %>% 
  summarize_at(.vars=c("TEMP","PRCP","RH"), .funs = list(min=min, mean=mean, max=max))

# monthly prcp
ggplot() + geom_col(data=fresyes_month, aes(x=MONTH, y=PRCP_mean, fill=TEMP_mean))+
  theme_minimal() + labs(y="", x="")+
  theme(plot.background = element_blank(),
        legend.position = "left",
        panel.border = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = unit(c(0, 0, 0 ,0), "mm")) +
  annotate("text", x=6.5, y = c(0,.5,1,1.5,2),label=c("0","0.5","1","1.5","2"), color="black", size=3) +
  scale_fill_viridis_c("Mean \nTemp (C)")+
  coord_polar()

# WEEK: filter to 1980 plus:
fresyes_week <- fresyes %>% filter(YEARMODA > "1980-01-01") %>% 
  filter(!is.na(PRCP)) %>% mutate(WEEK=lubridate::week(YEARMODA)) %>% 
  group_by(WEEK) %>% 
  summarize_at(.vars=vars(TEMP,PRCP,RH), .funs = list(min=min, mean=mean, max=max))

# Weekly mean tempcolor by PRECIP
ggplot() +
  geom_col(data=fresyes_week, aes(x=WEEK, y=TEMP_mean, fill=PRCP_mean))+
  theme_minimal() + labs(y="", x="")+
  theme(plot.background = element_blank(),
        legend.position = "left",
        panel.border = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = unit(c(0, 0, 0 ,0), "mm")) +
  annotate("text", x=1, y = c(0,10,20,30),label=c("0C","10C","20C","30C"), color="black", size=3) +
  scale_fill_viridis_c("Mean \nPrecip (in)")+
  coord_polar()

# Weekly PRECIP color by temp
ggplot() + geom_col(data=fresyes_week, aes(x=WEEK, y=PRCP_mean, fill=TEMP_mean))+
  coord_polar() + 
  scale_fill_viridis_c("Mean \nTemp (C)") + theme_minimal() + 
  labs(y="", x="") +
  theme(plot.background = element_blank(),
        legend.position = "left",
        panel.border = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = unit(c(0, 0, 0 ,0), "mm")) +
  annotate("text", x=27, y = c(0,.5,1,1.5,2),label=c("0","0.5","1","1.5","2"), color="blue")

```


